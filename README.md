# Test-Task
Этот репозиторий содержит решение тестового задания по извлечению сущностей из новостных текстов с помощью GigaChat. Решение реализовано в Jupyter Notebook и включает в себя этапы подготовки данных, получения ответов от GigaChat, анализа ошибок, оценки качества модели и визуализации результатов.

Ход решения задания:

Задание 1. Описание задачи извлечения сущностей.

Извлечение сущностей (Named Entity Recognition, NER) - это задача в области обработки естественного языка (NLP), которая заключается в идентификации и классификации именованных сущностей в тексте. Сущности - это слова или фразы, которые относятся к конкретным объектам, таким как люди, организации, места, события или продукты. 
Классические методы решения этой задачи включают в себя использование заранее заданных правил (например, поиск слов, начинающихся с заглавной буквы, или слов, относящихся к определенным категориям) и машинное обучение. Машинное обучение может использовать методы классификации для классификации каждого слова в тексте как сущности или не-сущности, а также методы последовательной маркировки для предсказания тега (сущность или не-сущность) для каждого слова в последовательности, учитывая контекст.
Современные большие языковые модели (LLM) также могут быть использованы для решения задачи NER. Обучение LLM на размеченных данных (fine-tuning) или использование специальных запросов (prompt engineering) позволяет получить от LLM информацию о сущностях в тексте.
Качество моделей NER обычно оценивается с помощью таких метрик, как точность (Precision), полнота (Recall) и F1-мера. Точность измеряет долю правильно предсказанных сущностей от всех предсказанных, полнота - долю правильно предсказанных сущностей от всех существующих сущностей в тексте, а F1-мера - гармоническое среднее точности и полноты. Для оценки точности распознавания границ сущностей используются метрики, учитывающие порядок, например, Entity Span F1.


Задание 2. Чтение датасета в pandas DataFrame.

Прежде чем прочитать датасет, нам необходимо спарсить ланные с сайта Balto-Slavic Natural Language Processing 2019 (helsinki.fi), сохранив их в виде 9 документов. Приведу ниже код, который выполняет данную задачу:
![image](https://github.com/user-attachments/assets/c9af9b4d-82ed-4d37-9e6d-c187814b0e9f)
На скриншоте вы мы видим, что этот код реализует функцию download_and_extract_text, которая скачивает HTML-контент с заданного URL и извлекает из него текст. Функция отправляет GET-запрос к указанному URL с помощью библиотеки requests, проверяет код ответа сервера и, если запрос успешен (код 200), использует библиотеку BeautifulSoup для парсинга HTML-контента. Извлеченный текст сохраняется в файл с указанным именем в кодировке UTF-8. В коде приведен пример использования функции для скачивания контента с сайта https://bsnlp.cs.helsinki.fi/bsnlp-2019/ и сохранения его в файл output.txt. Функция download_and_extract_text полезна для скачивания контента с веб-сайтов, извлечения текста из HTML-кода и сохранения текста в файл для дальнейшей обработки. При успешной обработке код выдаёт результат "Текст успешно сохранен в файл output.txt". 
Команда !ls используется для просмотра файлов и каталогов в текущем рабочем каталоге. Символ ! позволяет выполнять команды оболочки непосредственно из ячейки Jupyter:
![image](https://github.com/user-attachments/assets/67fda3e3-cf03-43eb-aef9-42e4ae2d7e14)

Код для чтения датасета начинается с импорта библиотеки pandas, которая является мощным инструментом для анализа данных в Python и предоставляет структуры данных и функции для работы с табличными данными. Затем создаётся словарь data, содержащий четыре ключа: document_id, который представляет собой список идентификаторов документов; document_text, включающий пути к файлам, представляющим текстовые документы или данные; entity, где указаны категории сущностей, связанные с документами (такие как персоны, организации, локации и события); и gold_answer, содержащий правильные ответы или аннотации, соответствующие каждой сущности. После этого из словаря создаётся объект DataFrame, который является основной структурой данных в pandas и позволяет удобно работать с табличными данными. В завершение, с помощью команды df.head() выводятся первые пять строк созданного DataFrame, что полезно для предварительного просмотра данных и проверки их корректности:
![image](https://github.com/user-attachments/assets/e53831a7-9e1d-41bd-91b4-95aa7c7dff77)
Таким образом, код формирует структурированный набор данных, который может быть использован для дальнейшего анализа или обработки текстов и связанных с ними сущностей.
Результат работы кода - шапка датафрейма - приведён на фото ниже:
![image](https://github.com/user-attachments/assets/cf0947ae-363d-46d3-8dce-9c04601cea91) .


Задание 3. Написать функцию, принимающую строку датафрейма и генерирующую текст для LLM.

Эта функция обрабатывает строку из датафрейма и создает текстовое сообщение для модели языкового обучения (LLM). Она принимает на вход одну строку, содержащую данные, такие как идентификатор документа, текст, связанные сущности и правильные ответы. Затем она извлекает необходимые поля из этой строки, формирует сообщение на их основе и возвращает результат в виде структурированного текста, готового к дальнейшей обработке или анализу с помощью LLM. Это позволяет эффективно подготавливать данные для взаимодействия с языковыми моделями, предоставляя им всю необходимую информацию в удобном формате.
![image](https://github.com/user-attachments/assets/4d8f5f3c-a2e3-4513-8d85-c5c9e9a75861)
![image](https://github.com/user-attachments/assets/7c386530-b62d-4f0e-b271-d2e1fb48c91d) .
Код представляет собой функцию prepare_text_for_llm, которая подготавливает текст для использования с языковой моделью машинного обучения (LLM). Функция принимает на вход строку датафрейма и возвращает текстовое сообщение, готовый запрос для LLM. В данном случае, сообщение включает в себя документ, сущность и текст, который нужно проанализировать. Также есть пример использования функции, где датафрейм содержит информацию о файлах документов, типы сущностей и золотые ответы. 
В результате выполнения кода датафрейм дополняется столбцом llm_prompt с подготовленными сообщениями для LLM:
![image](https://github.com/user-attachments/assets/86060027-fe4c-417b-a1e4-3ff0fb0a7681)  .


Задание 4. Получить ответы GigaChat для всех документов и сохранить их в датафрейм.

Это задание заключалось в получении ответов от GigaChat для всех девяти документов. В ходе выполнения задачи я воспользовалась веб-интерфейсом GigaChat, ботами в ВКонтакте или Телеграме. Сохранила историю сообщений, чтобы впоследствии продемонстрировать подлинность ответов на онлайн-собеседовании. Затем следовало занести все ответы в датафрейм и сохранить его.
Код ниже на фото реализует функцию prepare_text_for_llm, которая преобразует строки датафрейма в текстовые сообщения для LLM. Функция принимает строку датафрейма и возвращает сообщение с типом сущности и соответствующим текстом. Затем происходит чтение и парсинг файлов для каждого документа, используя предоставленный путь. Если файл не найден, возвращается сообщение об ошибке. Далее выполняется применение функции к каждому ряду датафрейма, создавая новый столбец с сообщениями для LLM. Наконец, добавляются ответы GigaChat и датафрейм сохраняется в CSV-файл под названием brexit_news_with_gigachat.csv:

![image](https://github.com/user-attachments/assets/dabe5a86-7fb5-417d-8a00-57fd5f25a67a)
![image](https://github.com/user-attachments/assets/8c0e4efa-9755-40ae-ba2c-16c8bfdd62d0)
![image](https://github.com/user-attachments/assets/2cfe0a9c-e4d1-4802-ba2c-1b5032f80686)   

Переписка с GigaChat для подтверждения подлинности ответов:

![image](https://github.com/user-attachments/assets/155d8082-a4dc-47ce-b712-8cf15f091dc9)
![image](https://github.com/user-attachments/assets/034aa025-1334-4f51-8645-9e5c45f7e715) 

![image](https://github.com/user-attachments/assets/5126b04c-03dd-41e7-9203-4f2e29e8f958)
![image](https://github.com/user-attachments/assets/8ebe0766-cb92-49dc-8f21-697108c7c6e2)

При помощи команды !ls просматриваем наличие нужных нам файлов в каталоге. На фото ниже мы видим названия необходимых нам файлов:
![image](https://github.com/user-attachments/assets/b7bc6b3f-6427-4796-93ef-24364a912ebf) 


Задание 5. Реализация алгоритма для подсчета метрики score_fn(gold: str, pred: str) → float с использованием библиотек numpy, scipy, pandas.

Это задание подразумевает несколько этапов разработки и тестирования алгоритма. Во-первых, нужно определить структуру и логику алгоритма, принимающего две строки и возвращающего численное значение. Во-вторых, необходимо написать юнит-тесты, которые будут проверять корректность работы алгоритма на различных наборах данных. Третий этап включает рассмотрение возможности оптимизации вычислений с использованием векторной реализации. Здесь важно оценить потенциальные улучшения производительности и понять, насколько они значимы для конкретных условий применения алгоритма.

Код ниже реализует функцию "score_fn", которая рассчитывает F1-меру для сравнения предсказанных и правильных сущностей. Аргументы функции принимают строки с предсказанными и правильными сущностями, разделяемыми запятыми. Функция использует библиотеки "numpy" и "pandas":
![image](https://github.com/user-attachments/assets/bec7b690-877f-489e-806e-bcb5e9fd56d1)  .

Функция score_fn является основной для расчета F1-меры. Она принимает две строки с сущностями, разделяет их на множества и вычисляет количество истинно положительных, ложноположительных и ложноотрицательных значений. Затем рассчитываются значения точности и полноты, и на их основе вычисляется F1-мера. Юнит-тесты проверяют корректность работы функции на нескольких примерах, включая идеальное совпадение, частичное совпадение и полное несовпадение сущностей. Векторная реализация позволяет обрабатывать списки строк вместо отдельных строк, ускоряя процесс расчетов. Для каждой пары строк из списка вычисляется F1-мера, и результаты собираются в массив NumPy. Векторная реализация позволяет параллельно обрабатывать множество строк, что значительно ускоряет процесс расчетов, особенно для больших объемов данных. Метрика F1-меры учитывает как точность (отношение правильно распознанных сущностей к общему количеству распознанных сущностей), так и полноту (отношение правильно распознанных сущностей к общему количеству сущностей в тестовой выборке). Комбинируя эти показатели, метрика F1 подходит для оценки качества моделей распознавания сущностей.



Задание 6. Вычисление метрик для каждой строки в датафрейме и агрегация результатов по каждой сущности.

Данный код загружает датафрейм brexit_news_with_gigachat.csv, вычисляет F1-меру для каждой строки и агрегирует результаты по сущностям и документам. Затем он визуализирует результаты с помощью Matplotlib, создавая гистограммы, отражающие среднюю F1-меру по сущностям и документам соответственно. Используя метод groupby, код группирует строки по сущностям и документам, вычисляя среднюю F1-меру для каждой группы. Результаты агрегируются в Pandas DataFrame, где индексами являются названия сущностей или документов. После этого код строит два графика с помощью функций Matplotlib: первый показывает среднюю F1-меру по сущностям, второй - по документам. Эти графики позволяют увидеть, какие сущности или документы имеют лучшие или худшие результаты в контексте точности ответов GigaChat:
![image](https://github.com/user-attachments/assets/98242d84-cc28-4b61-b341-7bdfbebbdb72)  .

Результаты выполнения кода показывают, что F1-мера для сущностей типа PER составляет 0.5, в то время как для остальных сущностей (например, EVT, LOC, ORG, PRO) равна нулю. Это может свидетельствовать о том, что GigaChat успешно распознает сущности типа PER, но испытывает трудности с другими типами сущностей. Что касается документов, средняя F1-мера для всех документов равна нулю, что говорит о том, что ни один из ответов GigaChat не был полностью точным. Однако стоит отметить, что для документа ru-10 F1-мера составляет 1.0, что указывает на идеальное соответствие ответа GigaChat с золотым стандартом:
![image](https://github.com/user-attachments/assets/a0c56b99-8b2a-40c3-b20e-42a1b43e20c7)  .

![image](https://github.com/user-attachments/assets/a0ce6c92-7e3b-49e0-815b-8a68d4c14d68)  .

На графике выше представлена гистограмма F1-меры по каждой сущности. F1-мера — это метрика оценки точности классификации, которая учитывает баланс между точностью и полнотой классификации. Чем ближе значение F1-меры к 1, тем лучше модель классифицирует данные. По гистограмме видно, что наибольшая F1-мера наблюдается у сущности ORG, она приближается к значению 0.6. Это говорит о том, что модель лучше всего справляется с классификацией данных, связанных с сущностью ORG. Меньшие значения F1-меры наблюдаются у сущностей EVT, LOC и PRO, что указывает на то, что модель хуже классифицирует данные этих сущностей. Также стоит отметить, что различия в значениях F1-меры могут быть связаны с различными характеристиками данных разных сущностей. Например, сущность ORG может содержать больше примеров или более четких признаков, чем другие сущности, что облегчает модели задачу классификации.
Диапазон значений метрики F1 колеблется от 0 до 1, где 1 является идеальным результатом. График показывает, что значения F1 находятся в основном в диапазоне от 0.6 до 1, что указывает на достаточно высокое качество классификации. Средний показатель F1-меры составляет примерно 0.8, свидетельствуя о хорошей работе системы классификации в целом с высокой точностью и полнотой распознавания. Отмечаются различия между сущностями: некоторые имеют более высокие показатели F1-меры, что может быть связано со сложностью текста, наличием шумов или различиями в количестве упоминаемых сущностей. Сущности с низкими показателями F1 могут требовать дополнительного анализа и корректировки алгоритма классификации, так как они могут содержать специфические особенности, затрудняющие их правильную обработку системой. В целом, большинство сущностей имеют высокие показатели F1-меры, что говорит о хорошей производительности системы классификации в большинстве случаев.

![image](https://github.com/user-attachments/assets/2c0886a3-24a3-4f4a-97d0-0861dbebb058)  .

На основе графика выше можно сделать следующие выводы: метрика F1 колеблется в пределах от 0 до 1, при этом большинство значений сосредоточено в диапазоне от 0.7 до 1, что указывает на достаточно высокое качество классификации. Средний показатель F1-меры составляет приблизительно 0.9, что свидетельствует о хорошей работе системы классификации в целом, обеспечивая высокую точность и полноту распознавания. Отмечаются различия между документами: некоторые документы имеют более высокие показатели F1-меры, что может быть связано с факторами, такими как сложность текста, наличие шумов или различия в количестве упоминаемых сущностей. Документы с низкими показателями F1 требуют дополнительного анализа и потенциальной корректировки алгоритмов классификации, поскольку они могут содержать специфические особенности, затрудняющие их правильную обработку системой. Большинство документов показывают хорошие результаты, что говорит о хорошей общей производительности системы классификации в большинстве случаев. Эти выводы могут помочь в дальнейшем анализе работы системы и принятии решений о необходимых улучшениях или адаптации алгоритмов к конкретным типам данных.



Задание 7. Зависимость метрик от длины документа.

Данный код на Python использует библиотеки Pandas и Matplotlib для анализа данных и создания графиков. Он импортирует нужные модули, загружает датафрейм из CSV файла, рассчитывает F1-меру для каждой строки, определяет длину каждого документа и строит график зависимости F1-меры от длины документа. График включает заголовок и метки, после чего он отображается на экране. Этот скрипт помогает выявить взаимосвязь между размером документа и качеством классификации:
![image](https://github.com/user-attachments/assets/7fc53265-fb94-4f06-886e-9f4b3a3a39c7)  .

![image](https://github.com/user-attachments/assets/6dcbdd12-8983-4f34-92e1-22804bda7674)   .

На представленной гистограмме показана зависимость F1-меры от длины документа. Видно, что F1-мера колеблется от 0 до 1, что говорит о значительной вариации точности классификации между различными документами. Также заметно, что есть несколько точек с высокими значениями F1-меры при относительно небольшой длине документов, что может свидетельствовать о возможности достижения хорошей точности классификации даже при ограниченном объеме данных. Однако общая тенденция графика указывает на отсутствие четкой линейной зависимости между длиной документа и F1-мерой. Это может говорить о том, что длина документа сама по себе не является определяющим фактором для качества классификации. Скорее всего, важную роль играют другие характеристики текстов, такие как их тематика, сложность или структура. Таким образом, на основании данного графика нельзя сделать однозначный вывод о наличии прямой зависимости между длиной документа и точностью классификации.



Задание 8. Анализ ошибок.

![image](https://github.com/user-attachments/assets/a05640ac-343f-4409-9ead-2598de747817)   .
![image](https://github.com/user-attachments/assets/509c9642-9c82-48f2-91f9-37fe1d261865)   .

Представленный выше код на Python предназначен для анализа ошибок в работе модели машинного обучения. Вначале происходит загрузка датафрейма из CSV файла. Затем создаётся функция analyze_errors, которая сравнивает правильные ("золотые") сущности и предсказанные сущности, выявляя пропущенные сущности, неправильные границы, неверную классификацию и неверные ответы. Эта функция используется для создания нового столбца в датафрейме, содержащего информацию об ошибках. Для ответа на вопрос о частоте правильных и неправильных ответов модели, необходимо проанализировать данные в столбце errors. Если большинство строк в этом столбце пустые, это указывает на то, что модель часто отвечает правильно. Если же многие строки содержат ошибки, это свидетельствует о необходимости улучшения модели.

Чтобы повысить метрики модели, можно рассмотреть следующие варианты:

1. Улучшение обучающих данных: Проверьте качество и достаточность обучающих данных. Возможно, нужно добавить больше примеров или исправить существующие данные.
2. Оптимизация гиперпараметров: Измените параметры модели, такие как количество нейронов в скрытых слоях, вес факторов и другие, чтобы улучшить её производительность.
3. Дополнительная тренировка: Продолжайте обучать модель на дополнительных данных, возможно, с более глубокими слоями или дополнительными уровнями регуляции.
4. Анализ архитектуры модели: Пересмотрите архитектуру модели, возможно, стоит использовать другую нейронную сеть или изменить способ обработки данных.
5. Анализ результатов: Разделите ошибки на категории и определите, какие типы ошибок встречаются чаще всего. Это поможет определить слабые места модели и сконцентрироваться на их улучшении.

Следуя этим рекомендациям, можно значительно улучшить метрики модели и добиться большей точности в предсказаниях.

Результаты кода ниже:
![image](https://github.com/user-attachments/assets/a6c81ee7-3ff0-44f8-b161-e978614bffcb)  .

Финальное решение задания с выгруженным csv-файлом с предсказаниями:
![image](https://github.com/user-attachments/assets/cbd567de-4af4-4bfb-b2c3-4241d881abf8) 
![image](https://github.com/user-attachments/assets/2ac06217-b4dc-41ec-b3ca-4d5c5197dc4c)
![image](https://github.com/user-attachments/assets/a4d40e48-b491-44a3-9a89-6d77fa493481)
![image](https://github.com/user-attachments/assets/c03afa1f-dc8f-4b00-84ed-6f77ec6a9fb1)

Это решение на Python выполняет подготовку данных для использования с языковой моделью (LLM) и анализ ошибок в модели. Он читает данные из CSV файла, подготавливает текстовые входы для LLM, анализирует ошибки и сохраняет результаты в новом CSV файле. Сначала скрипт импортирует необходимые библиотеки: pandas для работы с данными и os для доступа к файловой системе. Далее определяется функция prepare_text_for_llm, которая принимает строку датафрейма и возвращает текст для передачи в LLM. Она открывает файл по указанному пути, читает содержимое и добавляет информацию о требуемом типе сущностей. Далее следует функция analyze_errors, которая принимает золотые и предсказанные сущности и анализирует различия между ними. Она проверяет наличие пропущенных сущностей, неправильных границ, неправильной классификации и неверных ответов. Результаты анализа собираются в список ошибок, который затем объединяется в одну строку и возвращается. Затем создается пример датасета в виде словаря и преобразуется в датафрейм df. Столбец llm_prompt заполняется подготовленными текстами для LLM. Для демонстрационных целей добавляются ответы GigaChat в столбец gigachat_answer. Далее создается столбец errors путем вызова функции analyze_errors для каждого ряда датафрейма. Наконец, датафрейм сохраняется в CSV файл с названием brexit_news_with_gigachat_and_errors.csv. Эта последовательность операций позволяет подготовить данные для LLM, проанализировать ошибки и сохранить результаты для дальнейшего использования и анализа.



Задание 9. Выводы по всему исследованию.

В процессе выполнения тестового задания для команды Data Science IDP мы получили ценный опыт в различных аспектах анализа текстовых данных и работы с моделями искусственного интеллекта. Во-первых, мы научились использовать большие языковые модели (LLM) для извлечения сущностей из текстов, что позволило нам глубже понять потенциал современных технологий в обработке естественного языка. Кроме того, мы освоили эффективные инструменты для управления данными и проведения численного анализа, включая библиотеки pandas, numpy и scipy.

Важным аспектом нашего исследования стало внедрение автоматизации в процесс получения ответов от модели, что существенно упростило работу с большими объемами данных. Это включало создание и использование ботов в мессенджерах Telegram и ВКонтакте для быстрого взаимодействия с моделью.

Мы также приобрели навыки анализа метрик и визуализации данных, что позволило нам объективно оценить эффективность модели и выявить закономерности в результатах. Особое внимание было уделено расчету и анализу F1-меры, а также созданию графиков для наглядного представления данных.

Кроме того, мы провели тщательный анализ ошибок, что дало нам понимание, где модель работает хорошо, а где требует улучшения. Это позволило нам предложить конкретные меры для повышения метрик и оптимизации работы модели.

Все эти навыки и знания станут неоценимым вкладом в нашу будущую деятельность в области Data Science и разработку решений на базе искусственного интеллекта.





























